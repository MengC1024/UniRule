#!/usr/bin/env python3
"""
Unified Rules MCP Agent - Web Backend
ä¸ºå‰ç«¯ HTML é¡µé¢æä¾› API æœåŠ¡
æ”¯æŒå¤šç§è§„åˆ™è¯­è¨€ï¼ˆSnort, Splunk, Elasticç­‰ï¼‰
"""

import asyncio
import json
import os
import time
import uuid
from typing import Dict, Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from pydantic import BaseModel
from openai import AsyncOpenAI
from fastmcp import Client
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
)

# é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-1234")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.deepseek.com/v1")
MODEL = os.getenv("OPENAI_MODEL", "deepseek-chat")
MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://localhost:8000/mcp")

# System Prompt - å¯é€šè¿‡ç¯å¢ƒå˜é‡è‡ªå®šä¹‰
DEFAULT_SYSTEM_PROMPT = """You are a detection rule generation system.

Task: Given a detection context and target language, generate a detection rule.

Output the rule in a code block."""

SYSTEM_PROMPT = os.getenv("SYSTEM_PROMPT", DEFAULT_SYSTEM_PROMPT)

# æ˜¯å¦ä½¿ç”¨ [DONE] æ ‡è®°ï¼ˆå®éªŒæ¨¡å¼ä¸‹å»ºè®®å…³é—­ï¼‰
USE_DONE_MARKER = os.getenv("USE_DONE_MARKER", "false").lower() == "true"

# æ¯è½®å¯¹è¯æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
MAX_AGENT_ROUND = int(os.getenv("MAX_AGENT_ROUND", "5"))

# æ•°æ®æ¨¡å‹
class SessionCreate(BaseModel):
    enable_mcp: bool = True
    system_prompt: Optional[str] = None  # å…è®¸æ¯ä¸ªsessionè‡ªå®šä¹‰prompt


class ChatMessage(BaseModel):
    session_id: str
    message: str


# ä¼šè¯ç®¡ç†
class Session:
    def __init__(self, session_id: str, enable_mcp: bool = True, system_prompt: Optional[str] = None):
        self.session_id = session_id
        self.enable_mcp = enable_mcp
        self.system_prompt = system_prompt or SYSTEM_PROMPT
        self.mcp_client: Optional[Client] = None
        self.openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
        self.tools = []
        self.conversation_history = []
        self.is_finished = False
        
    async def initialize(self):
        """åˆå§‹åŒ–ä¼šè¯"""
        if self.enable_mcp:
            try:
                self.mcp_client = Client(MCP_SERVER_URL,timeout=120)
                await self.mcp_client.__aenter__()
                
                # è·å–å·¥å…·
                mcp_tools = await self.mcp_client.list_tools()
                print(f"å·²è·å– {len(mcp_tools)} ä¸ªå·¥å…·")
                print(mcp_tools)
                self.tools = [self._convert_tool_to_openai(tool) for tool in mcp_tools]
                
            except Exception as e:
                print(f"MCP è¿æ¥å¤±è´¥: {e}")
                self.enable_mcp = False
        
        # åˆå§‹åŒ–å¯¹è¯å†å²
        self.conversation_history = [
            {
                "role": "system",
                "content": self.system_prompt
            }
        ]
        
    async def cleanup(self):
        """æ¸…ç†ä¼šè¯"""
        if self.mcp_client:
            try:
                await self.mcp_client.__aexit__(None, None, None)
            except:
                pass
    
    def _convert_tool_to_openai(self, mcp_tool) -> dict:
        """è½¬æ¢å·¥å…·æ ¼å¼"""
        return {
            "type": "function",
            "function": {
                "name": mcp_tool.name,
                "description": mcp_tool.description,
                "parameters": mcp_tool.inputSchema
            }
        }
    
    async def call_tool(self, tool_name: str, arguments: dict) -> tuple[bool, str, Optional[str], float]:
        """è°ƒç”¨å·¥å…·ï¼Œè¿”å› (success, result, error, duration)"""
        try:
            start_time = time.time()
            result = await self.mcp_client.call_tool(tool_name, arguments)
            duration = (time.time() - start_time) * 1000
            return True, result.data, None, duration
        except Exception as e:
            return False, None, str(e), 0


# å…¨å±€ä¼šè¯å­˜å‚¨
sessions: Dict[str, Session] = {}


# FastAPI åº”ç”¨
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    yield
    # æ¸…ç†æ‰€æœ‰ä¼šè¯
    for session in sessions.values():
        await session.cleanup()


app = FastAPI(title="Unified Rules MCP Agent API", lifespan=lifespan)

# CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
async def serve_html():
    """æä¾›å‰ç«¯ HTML é¡µé¢"""
    html_path = "agent_frontend.html"
    if os.path.exists(html_path):
        return FileResponse(html_path)
    else:
        return {"message": "è¯·å°† HTML æ–‡ä»¶ä¿å­˜ä¸º agent_frontend.html"}


@app.post("/sessions")
async def create_session(session_create: SessionCreate):
    """åˆ›å»ºæ–°ä¼šè¯"""
    session_id = str(uuid.uuid4())
    session = Session(
        session_id, 
        session_create.enable_mcp,
        session_create.system_prompt
    )
    
    try:
        await session.initialize()
        sessions[session_id] = session
        
        return {
            "session_id": session_id,
            "enable_mcp": session.enable_mcp,
            "tools_count": len(session.tools)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")


@app.post("/chat/stream")
async def chat_stream(chat_message: ChatMessage):
    """æµå¼èŠå¤©"""
    session_id = chat_message.session_id
    user_message = chat_message.message
    
    if session_id not in sessions:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    
    session = sessions[session_id]
    
    if session.is_finished:
        raise HTTPException(status_code=400, detail="ä¼šè¯å·²ç»“æŸ")
    
    async def event_stream():
        """SSE äº‹ä»¶æµ"""
        try:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            session.conversation_history.append({
                "role": "user",
                "content": user_message
            })
            
            # æœ€å¤š MAX_AGENT_ROUND è½®å·¥å…·è°ƒç”¨ï¼Œ+1 è½®ç”¨äºæ— å·¥å…·æ—¶çš„æœ€ç»ˆè¾“å‡º
            for round_num in range(MAX_AGENT_ROUND + 1):
                # åˆ¤æ–­æ˜¯å¦è¿˜å…è®¸ä½¿ç”¨å·¥å…·
                allow_tools = session.enable_mcp and (round_num < MAX_AGENT_ROUND)
                
                # å¦‚æœè¾¾åˆ°å·¥å…·è°ƒç”¨ä¸Šé™ï¼Œé€šçŸ¥å‰ç«¯
                if session.enable_mcp and round_num == MAX_AGENT_ROUND:
                    yield f"data: {json.dumps({'type': 'warning', 'message': f'å·²è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨è½®æ¬¡({MAX_AGENT_ROUND})ï¼Œå°†ç›´æ¥è¾“å‡ºç»“æœ'})}\n\n"
                
                # è°ƒç”¨ OpenAI API
                response = await session.openai_client.chat.completions.create(
                    model=MODEL,
                    messages=session.conversation_history,
                    tools=session.tools if allow_tools else None,
                    tool_choice="auto" if allow_tools else None,
                    stream=True
                )
                logging.debug(f"Round {round_num}, allow_tools={allow_tools}, TOOLS:{session.tools if allow_tools else 'None'}")
                
                assistant_message_content = ""
                assistant_tool_calls = []
                
                # å¤„ç†æµå¼å“åº”
                async for chunk in response:
                    delta = chunk.choices[0].delta
                    
                    # å†…å®¹æµ
                    if delta.content:
                        assistant_message_content += delta.content
                        yield f"data: {json.dumps({'type': 'content', 'content': delta.content})}\n\n"
                    
                    # å·¥å…·è°ƒç”¨æµï¼ˆä»…åœ¨å…è®¸å·¥å…·æ—¶å¤„ç†ï¼‰
                    if allow_tools and delta.tool_calls:
                        for tool_call_delta in delta.tool_calls:
                            if tool_call_delta.index is not None:
                                idx = tool_call_delta.index
                                
                                # æ–°çš„å·¥å…·è°ƒç”¨
                                if idx >= len(assistant_tool_calls):
                                    assistant_tool_calls.append({
                                        "id": tool_call_delta.id or "",
                                        "type": "function",
                                        "function": {
                                            "name": tool_call_delta.function.name or "",
                                            "arguments": ""
                                        }
                                    })
                                
                                # ç´¯ç§¯å‚æ•°
                                if tool_call_delta.function.arguments:
                                    assistant_tool_calls[idx]["function"]["arguments"] += tool_call_delta.function.arguments
                
                # å®Œæˆå†…å®¹è¾“å‡º
                if assistant_message_content:
                    yield f"data: {json.dumps({'type': 'content', 'content': '', 'done': True})}\n\n"
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                assistant_message = {
                    "role": "assistant",
                    "content": assistant_message_content
                }
                
                if assistant_tool_calls:
                    assistant_message["tool_calls"] = assistant_tool_calls
                
                session.conversation_history.append(assistant_message)
                
                # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸ
                if not assistant_tool_calls:
                    # å¯é€‰ï¼šæ£€æŸ¥ [DONE] æ ‡è®°
                    if USE_DONE_MARKER and "[DONE]" in assistant_message_content:
                        session.is_finished = True
                        yield f"data: {json.dumps({'type': 'finish', 'message': 'ä»»åŠ¡å®Œæˆ'})}\n\n"
                    else:
                        yield f"data: {json.dumps({'type': 'done'})}\n\n"
                    break
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                all_success = True
                for tool_call in assistant_tool_calls:
                    tool_name = tool_call["function"]["name"]
                    tool_args_str = tool_call["function"]["arguments"]
                    
                    try:
                        tool_args = json.loads(tool_args_str)
                    except:
                        tool_args = {}
                    
                    # å‘é€å·¥å…·è°ƒç”¨å¼€å§‹äº‹ä»¶
                    yield f"data: {json.dumps({'type': 'tool_call_start', 'tool_name': tool_name, 'arguments': tool_args, 'reasoning': f'Calling {tool_name}'})}\n\n"
                    
                    # è°ƒç”¨å·¥å…·
                    success, result, error, duration = await session.call_tool(tool_name, tool_args)
                    
                    # å‘é€å·¥å…·ç»“æœäº‹ä»¶
                    yield f"data: {json.dumps({'type': 'tool_call_result', 'tool_name': tool_name, 'result': result, 'success': success, 'error': error, 'duration_ms': duration})}\n\n"
                    
                    if not success:
                        all_success = False
                    
                    # æ·»åŠ å·¥å…·ç»“æœåˆ°å†å²
                    session.conversation_history.append({
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "name": tool_name,
                        "content": result if success else f"Error: {error}"
                    })
                
                if not all_success:
                    yield f"data: {json.dumps({'type': 'warning', 'message': 'Some tool calls failed'})}\n\n"
                
                # ç»§ç»­ä¸‹ä¸€è½®
            
        except Exception as e:
            print(f"å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
    
    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )


@app.delete("/sessions/{session_id}")
async def delete_session(session_id: str):
    """åˆ é™¤ä¼šè¯"""
    if session_id in sessions:
        session = sessions[session_id]
        await session.cleanup()
        del sessions[session_id]
        return {"message": "ä¼šè¯å·²åˆ é™¤"}
    else:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "sessions_count": len(sessions),
        "mcp_url": MCP_SERVER_URL,
        "model": MODEL
    }


@app.get("/config")
async def get_config():
    """è·å–å½“å‰é…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    return {
        "model": MODEL,
        "mcp_url": MCP_SERVER_URL,
        "use_done_marker": USE_DONE_MARKER,
        "max_agent_round": MAX_AGENT_ROUND,
        "system_prompt_length": len(SYSTEM_PROMPT)
    }


if __name__ == "__main__":
    import uvicorn
    
    # æ£€æŸ¥ API Key
    if OPENAI_API_KEY == "your-api-key-here":
        print("âŒ é”™è¯¯: è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("\nè®¾ç½®æ–¹æ³•:")
        print("  export OPENAI_API_KEY='your-api-key'")
        print("  python agent_backend.py")
        exit(1)
    
    print("ğŸš€ å¯åŠ¨ Unified Rules MCP Agent åç«¯æœåŠ¡")
    print(f"ğŸ“¡ MCP æœåŠ¡å™¨: {MCP_SERVER_URL}")
    print(f"ğŸ¤– LLM æ¨¡å‹: {MODEL}")
    print(f"ğŸ”§ æœ€å¤§å·¥å…·è°ƒç”¨è½®æ¬¡: {MAX_AGENT_ROUND}")
    print(f"ğŸŒ è®¿é—®åœ°å€: http://localhost:20001")
    print()
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=20001,
        log_level="info"
    )